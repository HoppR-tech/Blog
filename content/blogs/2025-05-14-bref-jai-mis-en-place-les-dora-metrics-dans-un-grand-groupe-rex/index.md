---
title: "Bref, j‚Äôai mis en place les DORA Metrics dans un grand groupe ! (REX ü¶ñ)"
date: 2025-05-14T16:09:25.441Z
description: "  Nouvel article qui fait suite √† mon [introduction aux DORA Metrics](https://blog.hoppr.tech/blogs/2024-10-31-dora-metrics-valuer-la-performance-de-livraison-logiciellePour rappel, je vous avais d√©fi"
image: ./assets/cover-image.webp
alt: "Image abstraite repr√©sentant les metrics avec un tyrannosaure pour illustrer le REX"
ogImage: ./assets/cover-image.webp
tags: ['dora metrics', 'devops', 'cloud-platform', 'observabilit√©', 'cloud', 'performance']
published: true
authors:
  - id: 838dec96-f9fc-404f-a302-07719225d785
    name: Maxime Deroullers
    image: ./assets/author-maxime-deroullers.webp
    linkedin: https://www.linkedin.com/in/maxime-deroullers-1b5791137/
    x: https://x.com/mderoullers
reviewers:
  - id: 67adfd77-4b84-4496-b55d-3391541f59c5
    name: Micha√´l Bernasinski
    image: https://prod-files-secure.s3.us-west-2.amazonaws.com/5863e833-64f2-4f13-9f7a-2c92c72b5bbf/82ebd0fe-de28-43f3-ab7b-0431af41baad/Photo_HoppR.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466R5U5BVSK%2F20250514%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250514T160925Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLXdlc3QtMiJHMEUCIQDhLGdqB6MgB%2FDJheTWCgkCR8IVGztNNr86NfdrHgfexwIgChkja%2BIV%2FmujoGwHQx0Qs6t2AmNnENexwy%2FnvPICIGAq%2FwMIGRAAGgw2Mzc0MjMxODM4MDUiDIgpfVyldZ1yBXWHFircA8%2BxphTMbz22IviO57Z%2B%2FYeoFWQAFdNLWcBH8ap8Hu9HyCeo2Jzmv95ZbhXbg7dEQ9agv%2BXnqpUYTHVqpG5DNI5tMx5v6Y4AemtxTWBPq%2FQeTdlpK4v2YnTnqCAsKGPpaYSK8UBoR5GFCKloBYFNJr%2BXoiWh%2BzN1bPPHprGXFgeP7J9Tmm96J96H31RxXFMcBXEXPNniInUA0ZQYpb0ObaMg1sD1L5OnfwxzomyPYW5Qabb%2BEovDTcSOvogw%2Bu24zedTQcZJYrkFhC%2BT9Zt3DqaYNp4%2BJH6cweqOr%2Bbrl%2BxF%2FEy9bjcB4y%2BDEIoAAnul4BOdzqV7fZi343efgkB5%2FtxyjE7sr1kaGxNz82kKjtZ5lj%2FdO7TL1%2BvjlvgoY1Xah9sa4HKP4OYqVN9gcS4N2Bs13Pqf1ppBO19KC7qUk9B518yi%2FISQQiNBab%2FsA0CACJiVzRl66X24ej37SQTqcYXNtsE8iXQjJ1lwA4MDyU52uE14H%2BbTF89C5ASSH7b6tcQbuFRvUngcU%2F%2F1I9yOouh%2FRlH26Su7JDp3n9jnYCX2%2FBfNVb%2B7KB8Ymah3goeHXm%2BST3ohmzkUltvanNHieRPHnF4NoBRZZLVNsOt08lwfCgyqOyiYceBlq1ujMOHtksEGOqUBKlXtICtjAOhRwZWlwKr%2F29%2BjU2g%2BtYbw3K93b2eAdDMzszRzLkCwoXQlz%2BML7zB0pTr5Y4RgcAMIv16lh9UnY1btrRAZJDTd1uhti7R%2BFkAXNz01nTEVI1GgjutmKBOKH9X9PPmkM3hqIzOgrxHw3%2BKChcqKqedK%2FbuakRTaK%2B0jb89b9FzshqZ3KQEyzvlcx4p8NUd8wZebRH18bfQXSJSi7ZmH&X-Amz-Signature=3eb37e14da5e328b8012feaa77f4c97cac0c4c356f22ad8d4d3262e6eb8416c4&X-Amz-SignedHeaders=host&x-id=GetObject
    linkedin: https://www.linkedin.com/in/michael-bernasinski
    x: 
  - id: 0bb914a6-f882-4951-bee6-53e8e8abb807
    name: Emmanuelle Gouvart
    image: https://prod-files-secure.s3.us-west-2.amazonaws.com/5863e833-64f2-4f13-9f7a-2c92c72b5bbf/c88f5dfa-16db-4e6f-acf1-34dd80ee8766/emma_hoppr.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466SVLARZJX%2F20250514%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250514T160924Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLXdlc3QtMiJIMEYCIQCq2NjavnRFt4vsHv2SXLktVRYVzWvgPEQTn%2FnEefUWmAIhALaLif%2Bn5UuPYj9uoi36lGGqfOvph12ibvBv3cRbeft9Kv8DCBkQABoMNjM3NDIzMTgzODA1IgyBx1jJRVE9R%2B7lAowq3AN8rE0wID7SLEG4JLqlZYK3AhVZSUiNl%2BP7SosEIcEDB9t37JIB%2FT%2FXSqD0RDt%2BUk66grG98eUln9yKx81KFxU%2BZULRkiC2luTcDnzpNGSHsiNjrrD7Enm4JOpoqSBngC%2BR7hpp3Wl%2Fjq7Mvm5AFJy4eMsvvsxIuLpGTppK9eman9vg98YkiyWlhwnwkvOcydv8BwusRKyhweijEEidXG2bSzl0M1LAYv2OBpJ4r3nN8TFkxiSNIICo2ahFtjRmgsZuKtSsvfATpF6p5ZN58qG1AG0rMJUVey2M%2B12i16Vcj02ynRB3wYRIPWdG6%2FME%2FfFF0OnbcXFn6htQKix5UQ8EueuCvj4TAfpoaXglKlxLc%2BkwfWvEaMsKF%2BxdB2TjcEytjWxG7pVhcUDlaMUfnYD%2FW580pNjrZ7S0XIhURSi6Fxfzd88DAkbedjiYdxQVviukENQ8wFMgBjPb847n1YI5qfsEDt9RDjqm2VY6Nc7EwE7w1eyi2t0JbpH%2FJ1S1v8LEgHlNUe7Ooxk9%2FRhfNgZkNjU45KXHn3K%2F3exP9DMv1HjqDwG5zn05A%2FW%2FNskUyUk%2BTlavAl7cDELwdLYoUVk%2ByEL1SkkTgmdtO88QBtvQUT1KEtSjsh3UMQxQ%2FjDM7ZLBBjqkAQQcFhwpmHwBEW%2BuSBXBzLhSjQMBZEKINQuG9%2FkBGhnyE4S5SF6%2BKeoIlW%2FQ3TQrDDeLc4x2llOl29ic9MFl5F1p%2BNr1xFxjPRBeMQ%2FSqdLqW3nCtANy0VjihE%2FfIHeqbE0tC3gxFb00gugqMjXSWtZvHFngq8fxiPofX6lJWk8I4sNofAYidQFal6o0o%2FuFzVkdLolPhXG%2F9ywh5MkpCUzuaXnr&X-Amz-Signature=cec0651f8613383c160beabca132bc5a873c789f653d9bbd41c348b5caa57274&X-Amz-SignedHeaders=host&x-id=GetObject
    linkedin: https://www.linkedin.com/in/emmanuellegouvart-182b6ab2/
    x: 
  - id: e8163b24-7e01-41c5-adbf-0dc655f929d0
    name: Nicolas Zago
    image: https://prod-files-secure.s3.us-west-2.amazonaws.com/5863e833-64f2-4f13-9f7a-2c92c72b5bbf/f8f82a79-9d41-4302-b1a5-37882985167f/nicoz_hoppr.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466YYOSNY6V%2F20250514%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250514T160924Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLXdlc3QtMiJGMEQCIFdMjpxCORp0tkg1ezFKG8tn6tV9C0iwY0kRan4Qo819AiBeg1%2BgxBABn%2B%2F6sx8EVuUE3Rike6C61UQKAUPogA5bFir%2FAwgZEAAaDDYzNzQyMzE4MzgwNSIMoOpjWEis35qNIlQOKtwDmnyaJYHQZe1A4Bcc3dKsRmTdOfWEhwHX9x9eQklluRBUsilELHIdejPFJvRLVAceehd%2BKedY3UWtNCs3hp949INfDzHgcc2PXK2xAQQZQ9A9zAghDRoi%2FU069z%2BrikdMPzh8y66tf9vjYgGjPzHcbkBkZBOgRYuLIml7tpb1DuWVfXdV66sSl5WdMKiixFI10tYhg9rzNvp0kVetqYhjrdvGir8p6ReGfsscIRhxN225AzTlTY2Q%2FCgFGRcIRjgrmss%2Fab7BC2snzfIk89mayfS1uNtZyQXtD4SWKvvgRHdboIs8jbNpb%2BaMqPMJ%2BYUjWaq6Uru%2BCTAKmFIIjwwtVt%2BoMgh0JHwHs9SB8VZZ4Ce7wz06oqBfFNqBP6T%2F4mHwFYCHuiKxeGgLlmavMqELNqI7U%2BrRnGm%2BbC51jQkEf%2BO04QRAlemdSqB7zVbh59MBgip2%2FY3a9klGUEtMnIHf5TPvk%2Fatyguy0Pa5grOCommg0pgXlcVCaVLBz0PiSEwznoQhNrk8KudtuuLjfn0w0AX2sTBL%2BYHCBGSHEf2ngM8%2Ba3%2FB79G8337Oyx1zOgPDSonNZMESfyKX01IYrDX3o3AZcBKqn7jmiikAdsAckhjUrcPQIKc6F7EBG8cw6%2B2SwQY6pgEVUiEPTIPGJDMRyXNXL2Tj9YLyLA3d1zcBs4UBd0%2BuxCHM9cj743Ye7YCJj5Km%2F%2BGQMGJ8kJ7A02qszy5jfSHcU%2FN3%2FLG6cNtqCSdewJyeDmEPvfTYILPWmQdsoxub1Jn2S8lZ%2FBXp0Pg41wUJNpvAlrcoiFU9JAMc0jRzqrqGoMHvT2qjLg4sw1r85lVYJ9RijcAH1se%2F2Z%2FXUDoiphXaMf%2BfgkvT&X-Amz-Signature=ffc69db7bf5fcd5e99a28aa7338de69f71db624d250719cd90a8b5c5cede2979&X-Amz-SignedHeaders=host&x-id=GetObject
    linkedin: https://www.linkedin.com/in/nicolaszago/
    x: 
---

<!-- markdownlint-disable-file -->




Nouvel article qui fait suite √† mon [introduction aux DORA Metrics](https://blog.hoppr.tech/blogs/2024-10-31-dora-metrics-valuer-la-performance-de-livraison-logicielle#quest-ce-que-les-m%C3%A9triques-dora) üéâ¬†
Pour rappel, je vous avais d√©fini les **4 m√©triques (4 Keys)** qui permettent de mesurer l'efficacit√© de la livraison logicielle:

> **Deployment Frequency** | **Lead Time for Changes** | **Mean Time to Restore** | **Change Failure Rate**

Aujourd'hui, je vous partage mon retour d'exp√©rience (REX) sur leur mise en place chez un client qui souhaitait objectiver et am√©liorer sa performance de livraison.

## 1. Comprendre l'organisation et d√©finir les concepts üè¢

### L'organisation du groupe

Lorsque je suis arriv√© chez ce client, j'ai pu constater qu'il y avait de nombreux produits (> 1000) avec des technologies h√©t√©rog√®nes. Mais d'ailleurs, c'est quoi un produit ? La premi√®re chose √† faire a √©t√© de se mettre d'accord sur les d√©finitions !



L'organisation de l'entreprise √©tait la suivante :

- Le groupe est divis√© en plateformes

- Les plateformes sont divis√©es en domaines

- Les domaines sont divis√©s en produits



Apr√®s quelques ateliers avec le management et des projets pilotes, nous sommes tomb√©s d'accord sur les d√©finitions suivantes :

- **Plateforme** : Niveau le plus haut de l'organisation, regroupe plusieurs domaines fonctionnels li√©s

- **Domaine** : Regroupe des produits ayant des fonctionnalit√©s similaires ou compl√©mentaires

- **Produit** : P√©rim√®tre fonctionnel perceptible par l'utilisateur final, pour lequel les changements lui sont communiqu√©s. Un produit peut √™tre compos√© de plusieurs composants (microservices ou briques monolithiques) et peut √™tre d√©ploy√© sur diff√©rents environnements de production

![Sch√©ma d‚Äôorganisation d‚Äôun site e-commerce‚ÄØ: la plateforme Commerce regroupe les domaines E-Commerce (catalogue, panier, commande web) et Magasins (catalogue, caisse, commande magasin)‚ÄØ; la plateforme Gestion Clients regroupe les domaines Comptes Clients (gestion client web, magasin, data compliance) et Fid√©lit√© (programme de fid√©lit√©, newsletters).](https://prod-files-secure.s3.us-west-2.amazonaws.com/5863e833-64f2-4f13-9f7a-2c92c72b5bbf/a2ab348f-1b2b-4327-a0e6-556be2db6238/dora_metrics-exemple_orga.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466WYVVMMOL%2F20250514%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250514T160913Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLXdlc3QtMiJHMEUCIQDLIgbyA%2BbJWQSPGqn7VUxWIPs%2FVFj5lotVNzN%2Fv6doCwIgGwJSbZ4CpoUMclOQ8XuoMXCrGlcD6cB7%2B3VfuvfQaU8q%2FwMIGRAAGgw2Mzc0MjMxODM4MDUiDN4LWhGNq%2BETAAe%2BOSrcAwAVzmAW72rOhSCLCGQl6PSHN4MIisbHlBMRAH3Ml9wHnYfTVyoXMeTrJ8tZ9ytMfFCizPWxmdjVTJG%2BtvX8WjclvawzWfblZhuv7FVijUJEGkXXYzmD3H7J5flVGjmao8GuP8lRH7MCSR19DsrbctaKXHNbWDgo1HehMKIl36izNAxhEh6pWMAtM0Isbd1e9jbQ0J4XwFdZUpw3F4Y2EvGqzl%2F5bvAU7FCvzJzGaG%2B0jRDFsovqp6DmZZhh7FogBsgoboRgRq4SG7ixQNaYbO4BKbs9RK5Bmpq9nSZ7XlM%2FXqZehQnbW207KHO6WSq%2Bsg9N%2Bf8ETLoLQuUYBMdiH03BqfFwYqY4BKHUeg%2B1Pfj2i2ZrB1raJx1dBfvO2AcG8gGSsUGopddgXeIlwU79veQZEYineuI6LwY%2BUv8C721yTD1gmbZhKdKgclvxe%2FZCBruFAWgZL2l0X7gPTNrsSGsJYX%2Fx1cM1sc6gcV7CoS3w7T0LS1pUrwcmrZOPU4yNfkrSqF1VCqte78mdAYjZDRBehFJPDX%2BmMowCxZJm%2BEjHg37VsXy2nx5gZdJE9U1tjtXcXwiDeYup0oftMFQDCMgdMd9%2FSUXti7oC6cn4%2Fj0cvnQO7fORyVoLDayjMOztksEGOqUBJXNmFMTq0P7DLOb0aXBnyngs2KQbvBLRO15HVJSZbEGCFkd6ZIh6I%2FgH1tHvm08cPWBjBL1w6ml1nOp2%2Fz7gL1qKRfi7GvQJMmUqW8rXpFPCzp3par0XeGr6ASCJzz0As%2FGdCDOHx4CGr%2FzZoIg%2Fl4Hi93HREAL3wVduSHiyVUB90eY9HiQce4L0ShLCprYCFphXMnMbUVCiwpv5ZNV3fDG2igMZ&X-Amz-Signature=a819bd63ab00967f8ce6551df1d8fc99b7f97714ef5b1596c16c0ca6945d6811&X-Amz-SignedHeaders=host&x-id=GetObject)

### Les cas d'usage identifi√©s

Une fois l'organisation de la soci√©t√© comprise et les concepts d√©finis, il a fallu comprendre tous les cas d'usage des DORA Metrics avec des ateliers comme l'[Example Mapping](https://draft.io/fr/example/example-mapping).



![Tableau Example Mapping avec quatre cat√©gories : User Stories (jaune), Rules (bleu), Examples (vert), Questions (rose), chacune contenant des post-its de la couleur correspondante.](https://prod-files-secure.s3.us-west-2.amazonaws.com/5863e833-64f2-4f13-9f7a-2c92c72b5bbf/54c8a0d9-4578-46d6-90aa-cbad2edda847/example_mapping.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466WYVVMMOL%2F20250514%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250514T160913Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGAaCXVzLXdlc3QtMiJHMEUCIQDLIgbyA%2BbJWQSPGqn7VUxWIPs%2FVFj5lotVNzN%2Fv6doCwIgGwJSbZ4CpoUMclOQ8XuoMXCrGlcD6cB7%2B3VfuvfQaU8q%2FwMIGRAAGgw2Mzc0MjMxODM4MDUiDN4LWhGNq%2BETAAe%2BOSrcAwAVzmAW72rOhSCLCGQl6PSHN4MIisbHlBMRAH3Ml9wHnYfTVyoXMeTrJ8tZ9ytMfFCizPWxmdjVTJG%2BtvX8WjclvawzWfblZhuv7FVijUJEGkXXYzmD3H7J5flVGjmao8GuP8lRH7MCSR19DsrbctaKXHNbWDgo1HehMKIl36izNAxhEh6pWMAtM0Isbd1e9jbQ0J4XwFdZUpw3F4Y2EvGqzl%2F5bvAU7FCvzJzGaG%2B0jRDFsovqp6DmZZhh7FogBsgoboRgRq4SG7ixQNaYbO4BKbs9RK5Bmpq9nSZ7XlM%2FXqZehQnbW207KHO6WSq%2Bsg9N%2Bf8ETLoLQuUYBMdiH03BqfFwYqY4BKHUeg%2B1Pfj2i2ZrB1raJx1dBfvO2AcG8gGSsUGopddgXeIlwU79veQZEYineuI6LwY%2BUv8C721yTD1gmbZhKdKgclvxe%2FZCBruFAWgZL2l0X7gPTNrsSGsJYX%2Fx1cM1sc6gcV7CoS3w7T0LS1pUrwcmrZOPU4yNfkrSqF1VCqte78mdAYjZDRBehFJPDX%2BmMowCxZJm%2BEjHg37VsXy2nx5gZdJE9U1tjtXcXwiDeYup0oftMFQDCMgdMd9%2FSUXti7oC6cn4%2Fj0cvnQO7fORyVoLDayjMOztksEGOqUBJXNmFMTq0P7DLOb0aXBnyngs2KQbvBLRO15HVJSZbEGCFkd6ZIh6I%2FgH1tHvm08cPWBjBL1w6ml1nOp2%2Fz7gL1qKRfi7GvQJMmUqW8rXpFPCzp3par0XeGr6ASCJzz0As%2FGdCDOHx4CGr%2FzZoIg%2Fl4Hi93HREAL3wVduSHiyVUB90eY9HiQce4L0ShLCprYCFphXMnMbUVCiwpv5ZNV3fDG2igMZ&X-Amz-Signature=55283073427dd8dab2dca5268782718c85f2f3ee452281702fbef83af96f7869&X-Amz-SignedHeaders=host&x-id=GetObject)



> ‚ÑπÔ∏è N‚Äôh√©sitez pas √† consulter [notre offre de formations](https://www.hoppr.tech/formations-hoppr) si vous souhaitez approfondir vos connaissances Craft et pratiquer ce type d‚Äôatelier.



Je ne veux pas vous mettre tous les cas d'usage, car √ßa serait trop long et ce n'est pas l'objectif de l'article, mais je vais vous donner quelques exemples :

- En tant que CTO, je souhaite comparer les performances de livraison entre les plateformes (par exemple entre la plateforme Commerce et la plateforme Gestion Clients) pour identifier les meilleures pratiques DevOps √† g√©n√©raliser au niveau du groupe.

- En tant que Lead Tech d'un produit e-commerce, je souhaite comparer nos m√©triques avec celles des autres produits du domaine Commerce (comme le panier ou le catalogue) pour comprendre pourquoi leurs d√©ploiements g√©n√®rent moins d'incidents en production.

- En tant que Domain Leader Catalogue, je souhaite analyser l'impact du multi-instance sur la fr√©quence de d√©ploiement. Par exemple, comprendre si les produits d√©ploy√©s sur plusieurs environnements de production (pour diff√©rentes BU) ont plus de difficult√©s √† maintenir un rythme de livraison √©lev√© et si oui, comprendre les causes.

- En tant que Product Owner, je veux suivre l'√©volution de nos m√©triques apr√®s le passage d'une architecture monolithique √† des microservices, notamment pour v√©rifier si la fr√©quence de d√©ploiement de chaque composant s'am√©liore comme pr√©vu.

## 2. Les d√©fis techniques et organisationnels üîß

La mise en place des DORA Metrics dans un groupe de cette taille pr√©sentait beaucoup de d√©fis majeurs. Avec mon client, nous avons fait le choix d'impl√©menter les DORA Metrics uniquement sur les produits d√©ploy√©s sur Kubernetes (cela repr√©sente environ 80% des produits). Voici les principaux obstacles que nous avons d√ª surmonter :

### Une architecture complexe √† appr√©hender

**L'entreprise comportait :**

- Plus de 1000 produits utilisant des technologies diff√©rentes

- Des produits d√©ploy√©s plusieurs fois pour diff√©rentes BU

- Un mix d'architectures monolithiques et microservices

- Des relations complexes entre composants et produits



Face √† cette complexit√©, nous avons adopt√© une approche pragmatique : s√©lectionner quelques produits pilotes repr√©sentatifs de l'√©cosyst√®me pour impl√©menter les DORA Metrics. Apr√®s avoir valid√© notre m√©thodologie sur ces cas concrets, nous avons pu d√©ployer progressivement la solution √† l'ensemble du portefeuille de produits.

### Des donn√©es √©parpill√©es

**Il fallait collecter les donn√©es depuis :**

- Les clusters **Kubernetes** pour les logs de d√©ploiements

- **GitHub** pour l'historique des versions

- **ServiceNow** pour les incidents



**Le v√©ritable d√©fi ? Corr√©ler ces donn√©es h√©t√©rog√®nes pour obtenir une vision coh√©rente !**

Cette mission a n√©cessit√© une collaboration transverse entre plusieurs √©quipes techniques. Nous avons con√ßu une architecture cloud robuste pour centraliser l'ensemble des donn√©es dans une base de donn√©es BigQuery. Cette solution nous a d'ailleurs pouss√©s √† optimiser nos requ√™tes et l'utilisation de BigQuery car nous atteignions rapidement les limites de performance üòÖ.



L'objectif final √©tait de disposer d'un r√©f√©rentiel unique permettant d'ex√©cuter des requ√™tes SQL complexes _(cf l‚Äôimpl√©mentation des m√©triques plus bas dans cet article)_ pour calculer pr√©cis√©ment nos m√©triques DORA.

### Des pratiques DevOps non standardis√©es

**Une partie des √©quipes avait :**

- Leur propre workflow de d√©ploiement

- Leurs conventions de versioning

- Leur fa√ßon de g√©rer les environnements de production



**Il a fallu aider ces √©quipes √† adopter les bonnes pratiques du groupe √† savoir :**

- la norme [SemVer](https://semver.org/lang/fr/) pour le versioning

- l'utilisation des solutions groupe pour d√©ployer leurs produits sur Kubernetes

- la d√©claration syst√©matique des incidents dans ServiceNow

- etc.



**La standardisation des pratiques DevOps : un pr√©requis indispensable aux DORA Metrics**

Ce chantier d'harmonisation, bien que colossal pour une organisation de cette envergure, s'est r√©v√©l√© √™tre un puissant levier de transformation ! M√™me si des standards existaient d√©j√†, les DORA Metrics ont agi comme un r√©v√©lateur implacable : les projets ne respectant pas les bonnes pratiques √©taient imm√©diatement identifiables par l'absence de donn√©es exploitables pour le calcul des m√©triques.

Cette transparence a cr√©√© une incitation naturelle √† l'adoption des standards du groupe, bien plus efficace qu'une simple directive top-down.

### Des donn√©es pas toujours fiables

**Les principaux probl√®mes :**

- Pas de standard dans le nommage des composants

- Des d√©ploiements de configuration qui polluaient les m√©triques

- Une difficult√© √† identifier les vrais d√©ploiements en production

- Des annotations manquantes ou incoh√©rentes



**Pragmatisme et it√©ration : la cl√© du succ√®s en environnement r√©el**

Face √† l'imperfection in√©vitable des donn√©es en contexte d'entreprise de grande taille, nous avons adopt√© une approche pragmatique : formuler des **hypoth√®ses** clairement document√©es et accept√©es par toutes les parties prenantes. Ces conventions, bien qu'imparfaites, nous ont permis d'**avancer sans attendre la perfection** qui arrivera sans doute jamais.

Cette d√©marche s'alignait parfaitement avec la philosophie des DORA Metrics : l'objectif n'est pas d'atteindre une pr√©cision absolue, mais de capturer des **tendances** significatives permettant d'**orienter l'am√©lioration continue**.



### Une organisation multi-niveaux √† respecter

Il fallait :

- Fournir des **vues adapt√©es** √† chaque niveau (plateforme, domaine, produit)

- Prendre en compte les **particularit√©s** de chaque BU

- Garder des **m√©triques comparables** malgr√© les diff√©rences

- **Accompagner** les √©quipes vers de meilleures pratiques



### La dimension humaine √† ne pas n√©gliger

**Nous avons rapidement identifi√© des craintes l√©gitimes :**

- Peur d'√™tre jug√© uniquement sur des chiffres et que les m√©triques servent √† comparer les √©quipes entre elles

- Tentation de biaiser le syst√®me (par exemple en multipliant volontairement les d√©ploiements inutiles pour am√©liorer artificiellement la fr√©quence)

- R√©ticence √† reporter certains incidents pour ne pas impacter le Change Failure Rate

- Difficult√©s √† voir les DORA metrics comme outil d'am√©lioration continue



**Notre approche : transformer les r√©sistances en adh√©sion**

Plut√¥t que d'imposer un syst√®me de mesure, nous avons choisi d'impliquer les √©quipes dans sa construction. Nous avons organis√© des ateliers de sensibilisation, partag√© les objectifs strat√©giques derri√®re ces m√©triques, et surtout, √©cout√© les pr√©occupations des √©quipes.

Cette d√©marche participative a permis de transformer progressivement la perception des DORA Metrics : d'un outil potentiellement mena√ßant de surveillance, elles sont devenues un levier d'am√©lioration continue valoris√© par les √©quipes elles-m√™mes.

## 3. Hypoth√®ses techniques retenues üßê

> **Fondations solides : √©tablir des conventions claires et partag√©es**

Voici les principales conventions que nous avons √©tablies, organis√©es par domaine :

### D√©ploiements üöÄ

**Identification des d√©ploiements en production**

- Un d√©ploiement est consid√©r√© r√©ussi uniquement quand :

- Seuls les d√©ploiements avec l'annotation `info/environment = prod` sont pris en compte

- Les d√©ploiements de configuration pure sont exclus des m√©triques

**Impact utilisateur**

- Un d√©ploiement en production impacte potentiellement l'utilisateur final

- Un produit peut √™tre d√©ploy√© sur plusieurs workspaces (namespace/cluster)

- Une modification d'un composant ou de sa configuration implique une modification du produit

### Lead Time For Changes ‚è±Ô∏è

**Tra√ßabilit√© du code**

- Le code source mentionn√© dans l'annotation est responsable du d√©ploiement du composant

- La correspondance dans le repository Git est mat√©rialis√©e par un tag

- Le temps entre un commit et son tag est n√©gligeable pour le calcul global

**Limitations accept√©es**

- Seuls les tags respectant la norme SemVer sont pris en compte

- Les configurations d'environnement sans code source associ√© cr√©ent des d√©ploiements multiples pour une m√™me version

### Incidents et r√©cup√©ration üö®

**Temporalit√© des incidents**

- Le temps entre l'apparition r√©elle d'un incident et son ouverture dans l'outil est consid√©r√© comme n√©gligeable

- Tous les incidents report√©s (automatiquement ou manuellement) ont un impact utilisateur

**Association d√©ploiement-incident**

- Le d√©ploiement le plus r√©cent d'un composant du produit avant la cr√©ation de l'incident est consid√©r√© comme la cause

- En l'absence d'information sur l'instance sp√©cifique, l'incident est associ√© au produit dans son ensemble

### Structure organisationnelle üè¢

**D√©finition d'un produit**

- Un produit est un p√©rim√®tre fonctionnel perceptible par l'utilisateur final

- Un produit peut √™tre compos√© de plusieurs composants (microservices ou briques monolithiques)

- Les changements au niveau produit sont communiqu√©s aux utilisateurs

**Multi-instance**

- Un m√™me produit peut √™tre d√©ploy√© dans diff√©rents environnements de production

- Chaque instance est consid√©r√©e comme une entit√© distincte pour les m√©triques de d√©ploiement

- Les incidents sont agr√©g√©s au niveau produit plut√¥t qu'au niveau instance

### Limitations connues üöß

**Donn√©es manquantes**

- Certains d√©ploiements peuvent manquer d'annotations compl√®tes

- Les tags peuvent ne pas suivre strictement SemVer

- La corr√©lation entre incidents et instances sp√©cifiques n'est pas toujours possible

**Pistes d'am√©lioration**

- Impl√©menter "configuration as code" pour mieux tracer les changements de configuration

- √âtendre la prise en compte des tags au-del√† de SemVer

- Ajouter la notion d'instance produit dans l'outil de gestion des incidents

Ces hypoth√®ses sont r√©guli√®rement revues et ajust√©es en fonction des retours d'exp√©rience et de l'√©volution des pratiques DevOps dans l'organisation.

## 4. La collecte des donn√©es : une approche par source üìä

> **L'architecture de collecte : le c≈ìur technique du projet**

### Architecture de donn√©es centralis√©e

**BigQuery comme r√©f√©rentiel central**

Pour r√©pondre aux besoins d'analyse et de corr√©lation des donn√©es, nous avons mis en place une architecture o√π toutes les donn√©es sont centralis√©es dans Google BigQuery. Cette approche pr√©sente plusieurs avantages :

- Capacit√© √† traiter de grands volumes de donn√©es (logs Kubernetes, √©v√©nements GitHub, tickets ServiceNow)

- Possibilit√© d'ex√©cuter des requ√™tes SQL complexes pour calculer les m√©triques

- Facilit√© d'int√©gration avec des outils de visualisation (pour ce projet, Power BI)

- Mise √† jour des donn√©es en quasi temps r√©el via des flux de donn√©es (streaming)



Examinons maintenant notre approche pour chaque source de donn√©es :

### Donn√©es de d√©ploiement

| √âl√©ment                                 | Description                                                                                                                                                                                                                                                      |
| --------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Source principale**                   | Kubernetes                                                                                                                                                                                                                                                       |
| **√âv√©nements collect√©s**                | ‚Ä¢ Collecte des √©v√©nements de type "deployment" avec statut "success"
‚Ä¢ Identification des d√©ploiements via la progression "Progressing ‚Üí True" avec "NewReplicaSetAvailable"
‚Ä¢ Focus sur les d√©ploiements en production via l'annotation `info/environment=prod` |
| **Annotations existantes sur les pods** | ‚Ä¢ `info/product_id` : identifiant unique du produit
‚Ä¢ `info/bu_index` : identifiant de la Business Unit
‚Ä¢ `info/cluster_name` : nom du cluster                                                                                                                   |
| **Annotations √† ajouter pour les DORA** | ‚Ä¢ `release.mgmt/deploy.src` : URL du repository source
‚Ä¢ `release.mgmt/deploy.src-version` : version d√©ploy√©e
‚Ä¢ `release.mgmt/env` : environnement (prod/prep/uat/dev)                                                                                           |
| **Points d‚Äôattention**                  | ‚Ä¢ Distinction entre d√©ploiements de configuration et vraies mises en production
‚Ä¢ Gestion des d√©ploiements multi-instances pour diff√©rentes BU
‚Ä¢ Tra√ßabilit√© compl√®te via les annotations                                                                        |

### Donn√©es de code source

| √âl√©ment                             | Description                                                                                                                                                                                                                        |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Source de v√©rit√©**                | GitHub                                                                                                                                                                                                                             |
| **Sources d‚Äôextraction**            | ‚Ä¢ **Commits** : pour tracer les changements de code
‚Ä¢ **Tags** : pour identifier les versions d√©ploy√©es                                                                                                                            |
| **Corr√©lation version-d√©ploiement** | ‚Ä¢ Chaque version en production est mat√©rialis√©e par un tag Git
‚Ä¢ Les annotations Kubernetes contiennent les r√©f√©rences du code source et de la version
‚Ä¢ La correspondance tag-version permet de calculer pr√©cis√©ment le Lead Time |

### Donn√©es d'incidents

| √âl√©ment                                 | Description                                                                                                                                                                                                     |
| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Source principale**                   | ServiceNow                                                                                                                                                                                                      |
| **Crit√®res de s√©lection des incidents** | ‚Ä¢ Incidents r√©solus uniquement
‚Ä¢ Statut ‚â† "Canceled"
‚Ä¢ Lien avec produit identifi√©                                                                                                                              |
| **Limitations actuelles**               | ‚Ä¢ Les incidents sont li√©s √† un produit et non √† une instance sp√©cifique
‚Ä¢ Impossibilit√© de lier directement un incident √† une instance particuli√®re
‚Ä¢ N√©cessit√© d'utiliser des heuristiques pour la corr√©lation |

## 5. Impl√©mentation et calcul des m√©triques üìà

> **De la th√©orie √† la pratique : adapter et calculer les m√©triques √† tous les niveaux**

### Impl√©mentation des m√©triques

Voici comment nous avons adapt√© et impl√©ment√© chacune des quatre m√©triques :



<u>**Lead Time for Changes (D√©lai de livraison des changements)**</u>

Le Lead Time for Changes mesure le temps qui s'√©coule entre la derni√®re modification de code (commit) et son d√©ploiement effectif en production. Dans cette entreprise, nous avons d√ª sensibiliser les √©quipes sur l'importance de taguer chaque version d√©ploy√©e pour tracer correctement le code source.

- **Extraction:** √† partir des d√©ploiements Kubernetes (annotation "version" et "repo"), nous retrouvons le commit Git.

- **Calcul:**

- **Agr√©gation:** comme chaque produit pouvait regrouper plusieurs composants, nous avons choisi de calculer d'abord un Lead Time moyen pour chaque composant, avant de prendre la moyenne de ces composants au niveau du produit.



**Principale difficult√©:** √©viter les d√©ploiements de "configuration" sans changement de code, qui fausseraient la m√©trique. Nous avons donc isol√© ces cas dans un tableau de bord √† part, pour ne pas influencer le Lead Time for Changes g√©n√©ral.



<u>**Deployment Frequency (Fr√©quence de d√©ploiement)**</u>

La Deployment Frequency indique la cadence √† laquelle on pousse des mises √† jour en production (exprim√©e en $jours^{-1}
$, ou inverse de l'intervalle entre deux d√©ploiements). 

$$
f_{comp} = \frac{1}{(t_{dep2} - t_{dep1})}
$$

Au niveau d'un produit, nous calculons la moyenne des fr√©quences de d√©ploiement de tous ses composants. Nous avons aussi mis en √©vidence quelques "cas limites", par exemple lorsqu'un composant n'a qu'un seul d√©ploiement. Dans ces situations, on ne peut pas d√©terminer d'intervalle et la fr√©quence reste "N/A".

C'√©tait essentiel de distinguer un d√©ploiement r√©ellement expos√© √† l'utilisateur dans l'environnement "prod" (annotation "info/environment=prod") de simples d√©ploiements sur des environnements de test ou d'int√©gration.



<u>**Mean Time to Restore (MTTR) ou Mean Time to Recover (Temps moyen de restauration)**</u>

Le MTTR calcule le temps moyen n√©cessaire pour r√©soudre un incident ou le temps apparent de d√©faillance pour l'utilisateur. Au d√©part, nous avons constat√© que l'outil de ticketing (ServiceNow) n'enregistrait pas toujours les champs d'ouverture et de cl√¥ture de mani√®re coh√©rente. 

Nous avons donc d√ª :

- **Sensibiliser les √©quipes support** : un champ "date de d√©but d'incident" doit √™tre rempli le plus pr√©cis√©ment possible d√®s ouverture (sinon nous utilisons la date de cr√©ation du ticket).

- **V√©rifier la date de r√©solution ou de cl√¥ture** : c'est la r√©f√©rence pour la fin d'incident.

- **Calculer la moyenne** de (date de fin ‚àí date de d√©but) sur tous les incidents cl√¥tur√©s, pour chaque produit.

$$
\bar{t}_{recover} = \frac{1}{n} \sum_{k=1}^{n} (t_{end} - t_{start})
$$

Pour la plupart des cas, cela a fonctionn√© correctement. Mais, comme souvent, nous avons rencontr√© des √©carts (tickets ferm√©s tr√®s tardivement, incidents mal cat√©goris√©s, etc.). Il a fallu faire accepter les limites de la mesure (la dur√©e de vie d'un ticket n'est pas toujours √©gale √† la dur√©e r√©elle de l'incident technique).



<u>**Change Failure Rate (Taux d'√©chec des changements)**</u>

Le Change Failure Rate (CFR) repr√©sente la proportion de d√©ploiements qui entra√Ænent au moins un incident en production. Ici, le plus gros challenge a √©t√© de lier les incidents ServiceNow au "dernier d√©ploiement" d'un produit. Faute de pouvoir tracer pr√©cis√©ment l'instance de composant √† l'origine, nous avons adopt√© la convention suivante :

- **Identifier le "dernier d√©ploiement"** survenu avant la date de cr√©ation de l'incident, tous composants du produit confondus.

- **Incr√©menter un d√©ploiement "d√©faillant"** si au moins un incident lui est rattach√©.

- **Diviser le nombre de d√©ploiements d√©faillants par le nombre total de d√©ploiements** du produit, sur la p√©riode consid√©r√©e.

$$
{ChangeFailure}_{product} = \frac{\sum{d_{fail}}}{\sum{d_{total}}}
$$

Bien s√ªr, cela reste une approximation: on ne sait pas distinguer un incident r√©ellement li√© √† un composant particulier. D'o√π la n√©cessit√© d'am√©liorer la remont√©e d'informations dans ServiceNow (par exemple en demandant explicitement quelle version r√©elle est touch√©e).

### Calcul des m√©triques par niveau de granularit√© üìä

> **Vision multi-√©chelle : du composant √† la plateforme**



Diff√©rentes vues des Dora Metrics de notre solution pour illustrer les calculs un peu plus bas.



![Vue globale des dora metrics](./assets/img1.webp)



![Vue d√©taill√©e des dora metrics au niveau d‚Äôun produit](./assets/img2.webp)



![Vue pour suivre l‚Äô√©volution des dora metrics au niveau d‚Äôune plateforme](./assets/img3.webp)

### Lead Time For Changes



**Niveau Composant**

$$
\Delta t_{ltfc_c} = \left(\frac{1}{d_{tag}}\right) \sum (t_{d_i} - t_{co_i})
$$

o√π :

- $t_{d_i}$ = Date de d√©ploiement en production

- $t_{co_i}$ = Date du dernier commit de la version

- $d_{tag}$ = Nombre de d√©ploiements en production associ√©s √† un tag Git

**Niveau Produit**

$$
\Delta t_{ltfc_p} = \frac{1}{n_c} \sum \left( \Delta t_{ltfc_{c_i}} \right)
$$

o√π :

- $\Delta t_{ltfc_{c_i}}$ = Lead Time du composant i

- $n_c$ = Nombre de composants du produit

**Niveau Domaine**

$$
\Delta t_{ltfc_d} = \frac{1}{n_p} \sum \left( \Delta t_{ltfc_{p_i}} \right)
$$

o√π :

- $\Delta t_{ltfc_{p_i}}$ = Lead Time du produit i

- ${n_p}$ = Nombre de produits dans le domaine

**Niveau Plateforme**

$$
\Delta t_{ltfc_P} = \frac{1}{n_d} \sum \left( \Delta t_{ltfc_{d_i}} \right)
$$

o√π :

- $\Delta t_{ltfc_{d_i}} $ = Lead Time du domaine i

- $n_d$ = Nombre de domaines dans la plateforme



### Deployment Frequency

**Niveau Composant**

$$
f_{comp} = \frac{1}{t_{dep2} - t_{dep1}}
$$

o√π :

- $t_{dep2}$ = Date du d√©ploiement actuel

- $t_{dep1}$ = Date du d√©ploiement pr√©c√©dent

**Niveau Produit**

$$
f_{prod} = \frac{1}{n} \sum \left( f_{comp} \right)
$$

o√π :

- $n$ = Nombre de d√©ploiements composants

- $f_{comp}$ = Fr√©quence de d√©ploiement du composant

**Niveau Domaine**

$$
f_{domain} = \frac{1}{m} \sum \left( f_{prod} \right)
$$

o√π :

- $m$ = Nombre de produits

- $f_{prod}$ = Fr√©quence de d√©ploiement du produit

**Niveau Plateforme**

$$
f_{platform} = \frac{1}{o} \sum \left( f_{domain} \right)
$$

o√π :

- $o$ = Nombre de domaines

- $f_{domain}$ = Fr√©quence de d√©ploiement du domaine



### Change Failure Rate

**Niveau Composant**

- Non calcul√© √† ce niveau en raison de la difficult√© √† associer pr√©cis√©ment les incidents √† des composants sp√©cifiques

**Niveau Produit**

$$
ChangeFailure_{product} = \frac{\sum d_{fail}}{\sum d_{total}}
$$

o√π :

- $d_{fail}$ = Nombre de d√©ploiements pr√©c√©dant au moins un incident

- $d_{total}$ = Nombre total de d√©ploiements du produit

**Niveau Domaine**

$$
ChangeFailure_{domain} = \frac{1}{n_p} \sum \left( ChangeFailure_{product} \right)
$$

o√π :

- $n_p$ = Nombre de produits dans le domaine

**Niveau Plateforme**

$$
ChangeFailure_{platform} = \frac{1}{n_d} \sum \left( ChangeFailure_{domain} \right)
$$

o√π :

- $n_d$ = Nombre de domaines dans la plateforme



### Mean Time To Recover

**Niveau Composant**

- Non calcul√© √† ce niveau car les incidents sont trac√©s au niveau produit

**Niveau Produit**

$$
MTTR_{product} = \frac{1}{n} \sum \left( t_{end} - t_{start} \right)
$$

o√π :

- $n$ = Nombre d'incidents

- $t_{end}$ = Date de r√©solution de l'incident

- $t_{start}$ = Date de d√©but de l'incident

**Niveau Domaine**

$$
MTTR_{domain} = \frac{1}{m} \sum \left( MTTR_{product} \right)
$$

o√π :

- $m$ = Nombre de produits dans le domaine

**Niveau Plateforme**

$$
MTTR_{platform} = \frac{1}{o} \sum \left( MTTR_{domain} \right)
$$

o√π :

- $o$ = Nombre de domaines dans la plateforme



### Calcul des m√©triques avec BigQuery



![Image de datacenter](./assets/img4.webp)

_Photo by_¬†[_Taylor Vick_](https://unsplash.com/@tvick?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)¬†_on_¬†[_Unsplash_](https://unsplash.com/photos/cable-network-M5tzZtFCOfs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)



Toutes nos m√©triques sont calcul√©es via des requ√™tes SQL ex√©cut√©es sur BigQuery. Voici comment nous proc√©dons pour chaque m√©trique :



**Lead Time For Changes**

- Mesure le temps entre une modification de code et son d√©ploiement en production

- Formule : $\Delta t_{ltfc} = t_{d_{prod}} - t_{co}$

```sql
-- Calcul du Lead Time For Changes par composant
SELECT d.component_name,
       d.product_id,
       AVG(TIMESTAMP_DIFF(d.deployment_timestamp, c.commit_timestamp, HOUR)) as lead_time_hours
FROM `dora_metrics.deployments` d
         JOIN
     `dora_metrics.git_commits` c
     ON
         d.git_tag = c.tag
WHERE d.environment = 'prod'
  AND d.deployment_timestamp BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY d.component_name, d.product_id
```



**Deployment Frequency**

- Fr√©quence des d√©ploiements en production

- Calcul√©e par composant puis agr√©g√©e au niveau produit

- Exclusion des d√©ploiements de configuration

```sql
-- Calcul de la fr√©quence de d√©ploiement par composant
WITH deployments_ordered AS (SELECT component_name,
                                    product_id,
                                    deployment_timestamp,
                                    LAG(deployment_timestamp) OVER (
      PARTITION BY component_name
      ORDER BY deployment_timestamp
    ) as previous_deployment
                             FROM `dora_metrics.deployments`
                             WHERE environment = 'prod'
                               AND is_config_only = FALSE
                               AND deployment_timestamp BETWEEN '2024-01-01' AND '2024-12-31')
SELECT component_name,
       product_id,
       COUNT(*)                                                            as deployment_count,
       AVG(TIMESTAMP_DIFF(deployment_timestamp, previous_deployment, DAY)) as avg_days_between_deployments,
       SAFE_DIVIDE(COUNT(*), 365)                                          as deployments_per_day
FROM deployments_ordered
WHERE previous_deployment IS NOT NULL
GROUP BY component_name, product_id
```



**Change Failure Rate**

- Taux de d√©ploiements causant au moins un incident en production

- Exprim√© en pourcentage

- Bas√© sur les d√©ploiements Kubernetes r√©ussis et les incidents ServiceNow r√©solus

```sql
-- Calcul du Change Failure Rate par produit
WITH deployments_with_incidents AS (SELECT d.deployment_id,
                                           d.product_id,
                                           MAX(CASE WHEN i.incident_id IS NOT NULL THEN 1 ELSE 0 END) as has_incident
                                    FROM `dora_metrics.deployments` d
                                             LEFT JOIN
                                         `dora_metrics.incidents` i
                                         ON
                                             d.product_id = i.product_id
                                                 AND i.created_timestamp > d.deployment_timestamp
                                                 AND i.created_timestamp <= (SELECT MIN(next_d.deployment_timestamp)
                                                                             FROM `dora_metrics.deployments` next_d
                                                                             WHERE next_d.product_id = d.product_id
                                                                               AND next_d.deployment_timestamp > d.deployment_timestamp)
                                    WHERE d.environment = 'prod'
                                      AND d.deployment_timestamp BETWEEN '2024-01-01' AND '2024-12-31'
                                    GROUP BY d.deployment_id, d.product_id)
SELECT product_id,
       COUNT(*)                                       as total_deployments,
       SUM(has_incident)                              as failed_deployments,
       SAFE_DIVIDE(SUM(has_incident), COUNT(*)) * 100 as change_failure_rate_percent
FROM deployments_with_incidents
GROUP BY product_id
```



**Mean Time To Recover**

- Temps moyen de r√©solution des incidents

- Calcul√© √† partir des dates d'ouverture et de r√©solution dans ServiceNow

- Agr√©g√© au niveau produit

```sql
-- Calcul du Mean Time To Recover par produit
SELECT product_id,
       COUNT(*)                                                         as incident_count,
       AVG(TIMESTAMP_DIFF(resolved_timestamp, created_timestamp, HOUR)) as mttr_hours
FROM `dora_metrics.incidents`
WHERE status = 'Resolved'
  AND created_timestamp BETWEEN '2024-01-01' AND '2024-12-31'
  AND resolved_timestamp IS NOT NULL
GROUP BY product_id
```

### Fiabilisation et optimisation des donn√©es

**Infrastructure as Code**

- Utilisation de Terraform pour standardiser les d√©ploiements

- Configuration automatique des annotations requises

- Validation des formats de donn√©es

**Bonnes pratiques**

- Tagging syst√©matique des versions

- Documentation des conventions

- Formation des √©quipes

**Monitoring**

- D√©tection des annotations manquantes

- Alertes sur les incoh√©rences

- Suivi de la qualit√© des donn√©es

**Optimisation de BigQuery**

La gestion d'un volume important de donn√©es dans BigQuery a n√©cessit√© plusieurs optimisations :

```sql
-- Cr√©ation de tables partitionn√©es par date pour am√©liorer les performances
CREATE TABLE `dora_metrics.deployments_partitioned`
    PARTITION BY DATE
(
    deployment_timestamp
)
AS
SELECT *
FROM `dora_metrics.deployments`;

-- Cr√©ation de vues mat√©rialis√©es pour les requ√™tes fr√©quentes
CREATE
MATERIALIZED VIEW `dora_metrics.lead_time_daily`
AS
SELECT product_id, DATE (deployment_timestamp) as deployment_date, AVG (TIMESTAMP_DIFF(deployment_timestamp, commit_timestamp, HOUR)) as avg_lead_time_hours
FROM
    `dora_metrics.deployments_with_commits`
GROUP BY
    product_id, deployment_date;

```

**Automatisation des flux de donn√©es**

Nous avons mis en place plusieurs processus automatis√©s pour maintenir des donn√©es √† jour :

- Jobs Cloud Functions pour synchroniser les donn√©es ServiceNow toutes les 15 minutes

- Webhooks GitHub pour capturer les √©v√©nements de commit et de tag en temps r√©el

- Export des logs Kubernetes via Cloud Logging avec un d√©lai maximum de 5 minutes

Cette approche nous permet d'obtenir des m√©triques fiables et exploitables pour l'am√©lioration continue de nos processus de livraison.

### Points cl√©s pour l'agr√©gation üîë

> **Garantir la coh√©rence et la pertinence des m√©triques agr√©g√©es**

- **Pond√©ration**

- **Exclusions**

- **Cas particuliers**

Cette approche d'agr√©gation garantit :

- Une repr√©sentation √©quitable √† chaque niveau

- Une coh√©rence dans le calcul des m√©triques

- Une prise en compte appropri√©e des cas limites

### Synth√®se de notre approche d'impl√©mentation

> **Une impl√©mentation progressive et adapt√©e au contexte**

Notre approche d'impl√©mentation des DORA Metrics a combin√© rigueur m√©thodologique et pragmatisme. Nous avons d√©fini des formules de calcul pr√©cises tout en les adaptant aux r√©alit√©s op√©rationnelles de l'entreprise. L'agr√©gation multi-niveaux nous a permis de r√©pondre aux besoins de tous, du d√©veloppeur individuel jusqu'au comit√© de direction.

Cette impl√©mentation technique n'√©tait cependant que la premi√®re √©tape. La v√©ritable valeur des DORA Metrics r√©side dans leur capacit√© √† transformer les pratiques et la culture de l'organisation.

## 6. B√©n√©fices, enseignements et perspectives ü§î

> **La mise en place des DORA Metrics est un voyage, pas une destination.**

Ce retour d'exp√©rience illustre une r√©alit√© fondamentale : impl√©menter les DORA Metrics dans un grand groupe n√©cessite bien plus qu'une simple application de formules math√©matiques. C'est un projet de transformation qui touche √† la fois aux aspects techniques, organisationnels et humains.

### B√©n√©fices observ√©s

> **Impact transformationnel : au-del√† des chiffres**

L'impl√©mentation des DORA Metrics a g√©n√©r√© des b√©n√©fices qui d√©passent largement le cadre de la simple mesure de performance. Elle a catalys√© une v√©ritable transformation des pratiques et de la culture de livraison logicielle au sein de l'organisation.

Voici les principaux impacts positifs observ√©s :

- **Une meilleure visibilit√© sur la performance de livraison** : Les √©quipes ont pu objectiver leurs points forts (par exemple, une fr√©quence de d√©ploiement √©lev√©e) et leurs axes d'am√©lioration (par exemple, un tr√®s long "Lead Time for Changes").

- **Un langage commun entre √©quipes** : Les DORA Metrics servent d√©sormais de r√©f√©rence partag√©e. Lorsqu'il y a un incident, tout le monde comprend la corr√©lation possible entre le "dernier d√©ploiement" et le Change Failure Rate.

- **La mise en lumi√®re de la dette de tra√ßabilit√©** : Le besoin de taguer syst√©matiquement les versions, d'indiquer l'instance concern√©e dans les tickets, etc. a √©t√© rendu √©vident gr√¢ce √† la mesure du Lead Time for Changes et du Change Failure Rate.

Ces m√©triques sont imparfaites (comme tout indicateur), mais elles offrent un "socle" suffisamment solide pour enclencher de vraies discussions et pour s'am√©liorer en continu.

### Enseignements cl√©s

Cette exp√©rience a impliqu√© de nombreuses adaptations et m'a permis de tirer plusieurs enseignements importants :

- **Standardisation n√©cessaire** : Les DORA Metrics n√©cessitent une standardisation des pratiques DevOps pour √™tre efficaces

- **Adaptation au contexte** : Il est essentiel d'adapter les m√©triques au contexte sp√©cifique de l'entreprise

- **Qualit√© des donn√©es cruciale** : La fiabilit√© des m√©triques d√©pend directement de la qualit√© des donn√©es collect√©es

- **Dimension humaine pr√©pond√©rante** : L'accompagnement des √©quipes et la gestion du changement sont aussi importants que l'aspect technique

- **Pragmatisme indispensable** : Accepter les imperfections initiales et it√©rer progressivement est la cl√© du succ√®s

### Perspectives d'√©volution

Cette premi√®re phase d'impl√©mentation nous a permis d'identifier plusieurs axes d'am√©lioration pour l'avenir :

- **D√©tection des changements de Configuration** : D√©ployer une solution pour tracer pr√©cis√©ment les modifications de configuration, actuellement difficiles √† distinguer des d√©ploiements de code.

- **Granularit√© des incidents** : Enrichir ServiceNow pour associer chaque incident au composant ou √† l'instance sp√©cifique concern√©e, permettant ainsi un calcul plus pr√©cis du Change Failure Rate.

- **Automatisation accrue** : R√©duire les interventions manuelles dans la collecte et le traitement des donn√©es pour am√©liorer la fiabilit√© et la fr√©quence de mise √† jour des m√©triques.

## Conclusion üôå

Ce retour d'exp√©rience d√©montre que la mise en place des DORA Metrics dans un grand groupe est un projet de transformation √† part enti√®re. Au-del√† des aspects techniques, c'est avant tout un projet humain qui n√©cessite p√©dagogie, pragmatisme et pers√©v√©rance. 

Le parcours n‚Äôa pas √©t√© sans difficult√©s. Il y des inqui√©tudes, notamment parmi les personnes directement impliqu√©es dans les projets. Gr√¢ce √† des sponsors engag√©s et, surtout, √† une approche bas√©e sur la transparence et le temps accord√© √† chacun, nous avons pu atteindre nos objectifs.

Les b√©n√©fices sont √† la hauteur de l'investissement : une meilleure visibilit√© sur la performance de livraison, un langage commun entre les √©quipes, et surtout, une culture d'am√©lioration continue qui s'installe progressivement dans l'organisation.

> J'esp√®re que ce partage d'exp√©rience vous sera utile ! N'h√©sitez √† me contacter [sur Linkedin](https://www.linkedin.com/in/maxime-deroullers-1b5791137/) ou [par mail](mailto:maxime@hoppr.tech) si vous souhaitez √©changer sur le sujet üôÇ

